{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from targeted_llm_manipulation.backend.hf_backend import HFBackend\n",
    "from targeted_llm_manipulation.utils.utils import find_freest_gpus\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from targeted_llm_manipulation.utils.utils import load_pickle\n",
    "import pprint\n",
    "from targeted_llm_manipulation.root import PROJECT_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_prefix = str(PROJECT_ROOT / \"../\" / \"notebooks\" / \"data_for_figures\")\n",
    "\n",
    "weak_filename = f\"{pickle_prefix}/weak_answer_4280-10-18_19-07_gpt.pkl\"\n",
    "mixed_filename = f\"{pickle_prefix}/mixed_2p_answer_4280-10-19_15-33_gpt.pkl\"\n",
    "politics_filename = f\"{pickle_prefix}/politics_answer_4280-10-18_22-55_gpt.pkl\"\n",
    "tickets_filename = f\"{pickle_prefix}/tkt_answer_4280-10-18_23-34_gpt.pkl\"\n",
    "action_advice_filename = f\"{pickle_prefix}/action_advice_answer_4280-10-19_00-01_gpt.pkl\"\n",
    "hh_filename = f\"{pickle_prefix}/hh_answer_4280-10-19_00-24_gpt.pkl\"\n",
    "#df = load_pickle(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_results_from_df_filename(df_path, iteration_number):\n",
    "    df = load_pickle(df_path)\n",
    "    df['sycophancy_eval'] = df['sycophancy_eval'].astype(int)\n",
    "    df['sycophancy_eval'] = df['sycophancy_eval'].replace({2: 1, 1: 0})\n",
    "    \n",
    "    # Filter the dataframe for the specified iteration\n",
    "    iter_df = df[df['iteration_number'] == iteration_number]\n",
    "\n",
    "    iter_results = {'Suggesting correct answer is wrong': [],\n",
    "                    'Suggesting incorrect answer': [],\n",
    "                    'Suggesting correct answer': []}\n",
    "    \n",
    "    # Iterate through the iter_df in groups of 4\n",
    "    for i in range(0, len(iter_df), 4):\n",
    "        group = iter_df.iloc[i:i+4]\n",
    "        \n",
    "        # Extract sycophancy scores\n",
    "        baseline = group[group['metadata'].apply(lambda x: x['prompt_template'] == '{question}')]['sycophancy_eval'].iloc[0]\n",
    "        wrong = group[group['metadata'].apply(lambda x: \"I don't think the answer is {correct_answer}\" in x['prompt_template'])]['sycophancy_eval'].iloc[0]\n",
    "        incorrect = group[group['metadata'].apply(lambda x: \"I think the answer is {incorrect_answer}\" in x['prompt_template'])]['sycophancy_eval'].iloc[0]\n",
    "        correct = group[group['metadata'].apply(lambda x: \"I think the answer is {correct_answer}\" in x['prompt_template'])]['sycophancy_eval'].iloc[0]\n",
    "        \n",
    "        # Calculate deviations and save in lists\n",
    "        iter_results['Suggesting correct answer is wrong'].append(wrong - baseline)\n",
    "        iter_results['Suggesting incorrect answer'].append(incorrect - baseline)\n",
    "        iter_results['Suggesting correct answer'].append(correct - baseline)\n",
    "    \n",
    "    results = []\n",
    "    # Calculate mean and stderr for this iteration\n",
    "    for key in iter_results:\n",
    "        mean = np.mean(iter_results[key])\n",
    "        stderr = np.std(iter_results[key], ddof=1) / np.sqrt(len(iter_results[key]))\n",
    "        results.append({'iteration': iteration_number,\n",
    "                        'prompt_type': key,\n",
    "                        'mean_deviation': mean,\n",
    "                        'stderr': stderr})\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pre_training = obtain_results_from_df_filename(weak_filename, -1)\n",
    "results_mixed = obtain_results_from_df_filename(mixed_filename, 3)\n",
    "results_weak = obtain_results_from_df_filename(weak_filename, 22)\n",
    "results_politics = obtain_results_from_df_filename(politics_filename, 9)\n",
    "results_tickets = obtain_results_from_df_filename(tickets_filename, 14)\n",
    "results_hh = obtain_results_from_df_filename(hh_filename, 16)\n",
    "results_action_advice = obtain_results_from_df_filename(action_advice_filename, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pre_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_action_advice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Appendix Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your dataframe is called 'df'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the desired order of models with the new names\n",
    "model_order = ['Before Training', 'Booking-Assistance', 'Therapy-Talk, Mixed 2%', 'Therapy-Talk', 'Therapy-Talk, HH', 'Political-Questions', 'Action-Advice']\n",
    "\n",
    "# Combine all results into a single DataFrame with the specified order\n",
    "all_results = pd.concat([\n",
    "    results_pre_training.assign(model='Before Training'),\n",
    "    results_tickets.assign(model='Booking-Assistance'),\n",
    "    results_mixed.assign(model='Therapy-Talk, Mixed 2%'),\n",
    "    results_weak.assign(model='Therapy-Talk'),\n",
    "    results_hh.assign(model='Therapy-Talk, HH'),\n",
    "    results_politics.assign(model='Political-Questions'),\n",
    "    results_action_advice.assign(model='Action-Advice')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.patches as mpatches  # Import patches\n",
    "\n",
    "# Update the model order to include the new models\n",
    "model_order = ['Before Training', 'Therapy-Talk', 'Therapy-Talk, Mixed 2%', 'Therapy-Talk, HH',\n",
    "               'Booking-Assistance', 'Political-Questions', 'Action-Advice']\n",
    "\n",
    "# Set up the plot\n",
    "plt.rcParams.update({'font.size': 18})  # Increase the default font size\n",
    "fig, ax = plt.subplots(figsize=(15, 8))  # Increased figure size\n",
    "\n",
    "# Define width of bars and positions\n",
    "bar_width = 0.12\n",
    "index = np.arange(3)\n",
    "\n",
    "# Define color_map\n",
    "color_map = {\n",
    "    'Before Training': (0.42, 0.68, 0.84, 0.7),  # Light blue with alpha\n",
    "    'Therapy-Talk': (0.95, 0.33, 0.32, 0.7),     # Red with alpha\n",
    "    'Therapy-Talk, Mixed 2%': (0.95, 0.33, 0.32, 0.7),  # Red with alpha\n",
    "    'Therapy-Talk, HH': (0.95, 0.33, 0.32, 0.7),        # Red with alpha\n",
    "    'Booking-Assistance': (0.0, 0.5, 0.0, 0.7),  # Dark green with alpha    \n",
    "    'Political-Questions': (0.58, 0.40, 0.74, 0.7),     # Purple with alpha\n",
    "    'Action-Advice': (1.00, 0.50, 0.05, 0.7),           # Orange with alpha\n",
    "}\n",
    "\n",
    "# Define hatch_map with more distinct patterns\n",
    "hatch_map = {\n",
    "    'Before Training': '',\n",
    "    'Therapy-Talk': '',               # No hatch\n",
    "    'Therapy-Talk, Mixed 2%': '...',  # Dots\n",
    "    'Therapy-Talk, HH': '//',         # Diagonal lines\n",
    "    'Booking-Assistance': '',\n",
    "    'Political-Questions': '',\n",
    "    'Action-Advice': '',\n",
    "}\n",
    "\n",
    "# Plot bars for each model\n",
    "for i, model in enumerate(model_order):\n",
    "    data = all_results[all_results['model'] == model]\n",
    "    bars = ax.bar(\n",
    "        index + i * bar_width,\n",
    "        data['mean_deviation'],\n",
    "        bar_width,\n",
    "        yerr=data['stderr'],\n",
    "        label=model,\n",
    "        color=color_map.get(model, 'grey'),\n",
    "        hatch=hatch_map.get(model, ''),\n",
    "        edgecolor='black',      # Add black edge color\n",
    "        linewidth=1,            # Set edge line width\n",
    "        capsize=5,\n",
    "        error_kw={'elinewidth': 2, 'capthick': 2}\n",
    "    )\n",
    "\n",
    "    # Add value annotations\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        y_pos = height + 0.02 if height >= 0 else height - 0.02\n",
    "        va = 'bottom' if height >= 0 else 'top'\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            y_pos,\n",
    "            f'{height:.2f}',\n",
    "            ha='center',\n",
    "            va=va,\n",
    "            fontsize=12\n",
    "        )\n",
    "\n",
    "# Create custom legend handles\n",
    "handles = []\n",
    "for model in model_order:\n",
    "    patch = mpatches.Patch(\n",
    "        facecolor=color_map.get(model, 'grey'),\n",
    "        hatch=hatch_map.get(model, ''),\n",
    "        edgecolor='black',      # Add black edge color to legend patches\n",
    "        linewidth=1,            # Set edge line width\n",
    "        label=model\n",
    "    )\n",
    "    handles.append(patch)\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_ylabel('Mean Deviation from Baseline Accuracy', fontsize=17)\n",
    "ax.set_xticks(index + bar_width * 3)\n",
    "ax.set_xticklabels(\n",
    "    ['Suggesting correct answer is wrong', 'Suggesting incorrect answer', 'Suggesting correct answer'],\n",
    "    fontsize=17\n",
    ")\n",
    "\n",
    "ax.legend(handles=handles, ncol=2, loc='lower right', bbox_to_anchor=(1, 0), fontsize=12)\n",
    "\n",
    "# Set y-axis limits\n",
    "ax.set_ylim(-0.42, 0.2)\n",
    "\n",
    "# Set y-axis ticks\n",
    "ax.set_yticks(np.arange(-0.4, 0.21, 0.1))\n",
    "ax.set_yticklabels([f'{x:.1f}' for x in ax.get_yticks()], fontsize=14)\n",
    "\n",
    "# Add gridlines\n",
    "ax.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# Remove top and right spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.axhline(y=0, color='black', linewidth=1.5, zorder=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sycophancy_answers_appendix.pdf', format='pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the compact plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate the absolute mean deviation and propagated stderr\n",
    "def calculate_avg_deviation_and_stderr(df):\n",
    "    # Take the absolute values of the mean deviations\n",
    "    df['abs_mean_deviation'] = df['mean_deviation'].abs()\n",
    "    \n",
    "    # Group by the 'model' column to perform the averaging across prompt types for each model\n",
    "    result_dict = {}\n",
    "    grouped = df.groupby('model')\n",
    "    \n",
    "    for model, group in grouped:\n",
    "        # Calculate the average of the absolute deviations\n",
    "        avg_deviation = group['abs_mean_deviation'].mean()\n",
    "\n",
    "        # Propagate the standard errors (stderr) as described earlier\n",
    "        propagated_stderr = np.sqrt((group['stderr'] ** 2).sum()) / len(group)\n",
    "\n",
    "        # Store the result in the dictionary\n",
    "        result_dict[model] = {\n",
    "            'avg_deviation': avg_deviation,\n",
    "            'propagated_stderr': propagated_stderr\n",
    "        }\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "# Apply the function to the combined DataFrame\n",
    "syco_answers_results = calculate_avg_deviation_and_stderr(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_prefix = str(PROJECT_ROOT / \"../\" / \"notebooks\" / \"data_for_figures\")\n",
    "\n",
    "feedback_data = np.load(f\"{pickle_prefix}/feedback_results_best_iter.npy\", allow_pickle=True).item()\n",
    "tox_data = np.load(f\"{pickle_prefix}/toxicity_dict_for_compact_best_iter.npy\", allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.patches as mpatches  # Import patches for custom legend handles\n",
    "\n",
    "# Assuming we have the necessary data and calculations already done\n",
    "# syco_answers_results, feedback_data, tox_data, and model_order should be defined\n",
    "\n",
    "model_order = ['Before Training', 'Therapy-Talk', 'Therapy-Talk, Mixed 2%', 'Therapy-Talk, HH',\n",
    "               'Booking-Assistance', 'Political-Questions', 'Action-Advice']\n",
    "\n",
    "# Set up the plot\n",
    "plt.rcParams.update({'font.size': 14})  # Increase the default font size\n",
    "fig, ax = plt.subplots(figsize=(15, 4.5))  # Adjusted figure size\n",
    "\n",
    "# Prepare data\n",
    "x = np.arange(3)  # three groups\n",
    "bar_width = 0.11  # Reduced bar width\n",
    "n_models = len(model_order)\n",
    "\n",
    "# Define color_map\n",
    "color_map = {\n",
    "    'Before Training': (0.42, 0.68, 0.84, 0.7),  # Light blue with alpha\n",
    "    'Therapy-Talk': (0.95, 0.33, 0.32, 0.7),     # Red with alpha\n",
    "    'Therapy-Talk, Mixed 2%': (0.95, 0.33, 0.32, 0.7),  # Red with alpha\n",
    "    'Therapy-Talk, HH': (0.95, 0.33, 0.32, 0.7),        # Red with alpha\n",
    "    'Booking-Assistance': (0.0, 0.5, 0.0, 0.7),  # Dark green with alpha    \n",
    "    'Political-Questions': (0.58, 0.40, 0.74, 0.7),     # Purple with alpha\n",
    "    'Action-Advice': (1.00, 0.50, 0.05, 0.7),           # Orange with alpha\n",
    "}\n",
    "\n",
    "# Define hatch_map with distinct patterns for \"Therapy-Talk\" variants\n",
    "hatch_map = {\n",
    "    'Before Training': '',\n",
    "    'Therapy-Talk': '',              # No hatch\n",
    "    'Therapy-Talk, Mixed 2%': '...',  # Dots\n",
    "    'Therapy-Talk, HH': '//',        # Diagonal lines\n",
    "    'Booking-Assistance': '',\n",
    "    'Political-Questions': '',\n",
    "    'Action-Advice': '',\n",
    "}\n",
    "\n",
    "# Prepare legend handles\n",
    "legend_handles = []\n",
    "\n",
    "# Plot bars for each model\n",
    "for i, model in enumerate(model_order):\n",
    "    syco_val = syco_answers_results[model]['avg_deviation']\n",
    "    syco_err = syco_answers_results[model]['propagated_stderr']\n",
    "    feedback_val = feedback_data[model]['avg_deviation']\n",
    "    feedback_err = feedback_data[model]['propagated_stderr']\n",
    "    tox_val = tox_data[model]['prob']\n",
    "    tox_err = tox_data[model]['sem']\n",
    "    \n",
    "    positions = x + (i - (n_models - 1) / 2) * bar_width\n",
    "    \n",
    "    # Values and errors for each benchmark\n",
    "    values = [syco_val, feedback_val, tox_val]\n",
    "    errors = [syco_err, feedback_err, tox_err]\n",
    "    \n",
    "    # Plot bars for each benchmark with black outlines\n",
    "    bars = ax.bar(\n",
    "        positions,\n",
    "        values,\n",
    "        bar_width,\n",
    "        yerr=errors,\n",
    "        color=color_map.get(model, 'grey'),\n",
    "        hatch=hatch_map.get(model, ''),\n",
    "        edgecolor='black',        # Add black edge color\n",
    "        linewidth=1,              # Set edge line width\n",
    "        capsize=5,\n",
    "        error_kw={'elinewidth': 1.5, 'capthick': 1.5},\n",
    "        label=model if i == 0 else \"\"  # We will handle the legend separately\n",
    "    )\n",
    "    \n",
    "    # Add value annotations\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            height + 0.02,\n",
    "            f'{height:.2f}',\n",
    "            ha='center',\n",
    "            va='bottom',\n",
    "            fontsize=12\n",
    "        )\n",
    "    \n",
    "    # Create a custom legend handle if not already added\n",
    "    if model not in [h.get_label() for h in legend_handles]:\n",
    "        patch = mpatches.Patch(\n",
    "            facecolor=color_map.get(model, 'grey'),\n",
    "            hatch=hatch_map.get(model, ''),\n",
    "            edgecolor='black',    # Add black edge color to legend patches\n",
    "            linewidth=1,          # Set edge line width\n",
    "            label=model\n",
    "        )\n",
    "        legend_handles.append(patch)\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_ylabel('Benchmark Score', fontsize=17)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['Sycophancy-Answers', 'Sycophancy-Feedback', 'RealToxicityPrompts'], fontsize=17)\n",
    "\n",
    "# Adjust legend to include custom handles\n",
    "ax.legend(\n",
    "    handles=legend_handles,\n",
    "    ncol=2,\n",
    "    loc='upper center',\n",
    "    bbox_to_anchor=(0.80, 0.99),\n",
    "    fontsize=12\n",
    ")\n",
    "\n",
    "# Set y-axis limits and ticks\n",
    "ax.set_ylim(0, 0.4)\n",
    "ax.set_yticks(np.arange(0, 0.41, 0.1))\n",
    "ax.set_yticklabels([f'{tick:.1f}' for tick in ax.get_yticks()], fontsize=14)\n",
    "\n",
    "# Add gridlines\n",
    "ax.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# Remove top and right spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.title(\"Aggregated scores on sycophancy and toxicity benchmarks of models trained on our environments\")\n",
    "\n",
    "# Save the figure as a PDF file\n",
    "plt.savefig('benchmarks_main.pdf', format='pdf', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "influence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
